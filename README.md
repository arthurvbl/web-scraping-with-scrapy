# ğŸ“¦ Web scraping with scrapy
Este Ã© um repositÃ³rio criado para explorar as utilidades e aplicaÃ§Ãµes do framework Scrapy para o web scraping.

## ğŸ¯ Objetivos
* Entender a estrutura e os componentes de um projeto Scrapy.
* Praticar extraÃ§Ã£o de informaÃ§Ãµes em pÃ¡ginas estÃ¡ticas
* Explorar boas prÃ¡ticas de raspagem de dados, como:
  * Pausas entre requisiÃ§Ãµes.
  * Tratamento de erros.
  * Armazenamento incremental dos dados (â€œsaving as you goâ€).
 
## ğŸ› ï¸ Tecnologias
* **Python 3.12.3**
* **Scrapy**
* **MongoDB**

## ğŸ“‚ Estrutura do projeto
```bash
scrapy-study/
â”‚â”€â”€ scrapy.cfg                # ConfiguraÃ§Ã£o principal do Scrapy
â”‚â”€â”€ requirements.txt          # DependÃªncias do projeto
â”‚
â”œâ”€â”€ myspider/                 # MÃ³dulo principal do Scrapy
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ items.py              # Estrutura dos dados coletados
â”‚   â”œâ”€â”€ middlewares.py        # Middlewares (tratamento de requests/responses)
â”‚   â”œâ”€â”€ pipelines.py          # DefiniÃ§Ã£o do pipeline de dados
â”‚   â”œâ”€â”€ settings.py           # ConfiguraÃ§Ãµes do projeto
â”‚   â””â”€â”€ spiders/              # Onde ficam os spiders
â”‚       â””â”€â”€ exemplo_spider.py
â”‚
â””â”€â”€ README.md                 # Este arquivo
```

## ğŸš€ Como executar
1. Clone o repositÃ³rio
```bash
git clone https://github.com/arthurvbl/web-scraping-with-scrapy.git
cd web-scraping-with-scrapy
```
2. Crie um ambiente virtual
```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
```
3. Instale as dependÃªncias
```bash
pip install -r requirements.txt
```
4. Execute um spide de exemplo
```bash
scrapy crawl exemplo_spider -o resultados.json
```

## ğŸ“Š Armazenamento dos dados
Os dados raspados podem ser armazenados em:
* JSON/CSV (export direto via Scrapy).
* MongoDB (pipeline configurado no `pipelines.py`   

Exemplo de exportaÃ§Ã£o para MongoDB (ajustar credenciais no settings.py):
```bash
ITEM_PIPELINES = {
   "myspider.pipelines.MongoPipeline": 300,
}
```

---

ğŸ“Œ Nota: O scraping deve sempre respeitar os termos de uso do site, o `robots.txt` e questÃµes legais de uso dos dados.

---
